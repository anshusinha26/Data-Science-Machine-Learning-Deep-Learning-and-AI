{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-oRijAoUwpp2Qlz-Kl3k6hNlodWQyf87","timestamp":1684044552809}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing Tools"]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"3NusV4oJ5XrI","executionInfo":{"status":"ok","timestamp":1684044918817,"user_tz":-330,"elapsed":516,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["data = pd.read_csv('Data.csv')\n","\n","# iloc takes the indexes of both the rows and columns, the rows and columns are\n","# separated by ','\n","X = data.iloc[:, :-1].values # features, all the columns except the last one\n","Y = data.iloc[:, -1].values # dependent variables, only the last column"],"metadata":{"id":"bR4ShQdA6t3I","executionInfo":{"status":"ok","timestamp":1684049405800,"user_tz":-330,"elapsed":459,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytG8dReCAb_L","executionInfo":{"status":"ok","timestamp":1684049407799,"user_tz":-330,"elapsed":18,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"63368de9-29b1-45db-dc8f-29a697a08b80"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqWQebAmAdVT","executionInfo":{"status":"ok","timestamp":1684049398020,"user_tz":-330,"elapsed":15,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"0a083a4f-91b1-4f5d-e1d2-0de24ea3f6da"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"code","source":["# The SimpleImputer class is used for handling missing values in a dataset\n","from sklearn.impute import SimpleImputer\n","\n","# creates an instance of SimpleImputer with the missing_values parameter set to \n","# np.nan and the strategy parameter set to 'mean'\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","\n","# fits the SimpleImputer instance imputer to the columns 1 and 2 \n","# (indexing starts from 0) of the array X\n","imputer.fit(X[:, 1:3])\n","# applies the transformation using the fitted SimpleImputer instance imputer to \n","# the columns 1 and 2 (indexing starts from 0) of the array X\n","X[:, 1:3] = imputer.transform(X[:, 1:3])\n","\n"],"metadata":{"id":"7NYU8CqLC4ls","executionInfo":{"status":"ok","timestamp":1684049441079,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQmjvFG5Ea1h","executionInfo":{"status":"ok","timestamp":1684049447946,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"47087425-c3b8-4ef3-9b0e-e981a43905cc"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","source":["# The ColumnTransformer class is part of scikit-learn and is used for applying \n","# different transformations to different columns of a dataset\n","from sklearn.compose import ColumnTransformer\n","\n","# The OneHotEncoder class is used for converting categorical features into a \n","# one-hot encoded representation. It transforms categorical variables into a \n","# binary vector format where each category is represented by a binary feature column\n","from sklearn.preprocessing import OneHotEncoder\n","\n","#  creates a ColumnTransformer named ct with a single transformation\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","\n","# The code x = np.array(ct.fit_transform(x)) applies the ColumnTransformer \n","# transformation specified by ct to the array x, and then converts the \n","# transformed result into a NumPy array.\n","X = np.array(ct.fit_transform(X))"],"metadata":{"id":"atMA1pUDFTLx","executionInfo":{"status":"ok","timestamp":1684049464119,"user_tz":-330,"elapsed":27,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AL1gxaleH7Yf","executionInfo":{"status":"ok","timestamp":1684049468074,"user_tz":-330,"elapsed":22,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"c20e5ff7-e36e-48ab-cabd-1890d89dca55"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","source":["# The LabelEncoder class is used for encoding categorical labels (i.e., target \n","# variables or class labels) with numerical values\n","from sklearn.preprocessing import LabelEncoder\n","\n","# creates an instance of the LabelEncoder class and assigns it to the variable le\n","le = LabelEncoder()\n","\n","# fits the LabelEncoder instance le to the array y and transforms the labels \n","# into their encoded numerical representation\n","Y = le.fit_transform(Y)"],"metadata":{"id":"P2qrSPw8Ijvd","executionInfo":{"status":"ok","timestamp":1684049479100,"user_tz":-330,"elapsed":528,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["print(Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5dNbOjH8IwZA","executionInfo":{"status":"ok","timestamp":1684049483177,"user_tz":-330,"elapsed":26,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"5d4b9c67-5163-47c5-b641-087b74b8ada8"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["# The train_test_split function is commonly used for splitting a dataset into \n","# training and testing subsets\n","from sklearn.model_selection import train_test_split\n","\n","# splits the arrays X and Y into training and testing sets using the \n","# train_test_split function. The resulting splits are assigned to the \n","# variables X_train, X_test, Y_train, and Y_test\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1) # The random_state parameter in the train_test_split function is used to set the random seed for the random number generator. By setting the random seed to a specific value, such as 1 in your example, you ensure that the random shuffling and splitting of the data will be reproducible"],"metadata":{"id":"jAhUfpgqLc9E","executionInfo":{"status":"ok","timestamp":1684050024260,"user_tz":-330,"elapsed":500,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rfc_ATs8M5tH","executionInfo":{"status":"ok","timestamp":1684050026072,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"464138a1-ff57-41f6-f74a-931fda3c12dd"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkJoFEivM5pQ","executionInfo":{"status":"ok","timestamp":1684050029156,"user_tz":-330,"elapsed":19,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"1096d0c1-7589-45df-9838-153a41e25a7d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(Y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYXuMdgBM5lo","executionInfo":{"status":"ok","timestamp":1684050031912,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"0c66883f-eabd-4aaa-e041-c01f1199153c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","source":["print(Y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhCorOyzM5VR","executionInfo":{"status":"ok","timestamp":1684050034728,"user_tz":-330,"elapsed":18,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"dd10e140-c9cc-40d4-c9cd-7a76014f98e5"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["## Feature Scaling"]},{"cell_type":"code","source":["# The StandardScaler class is used for standardizing features by removing the \n","# mean and scaling to unit variance\n","from sklearn.preprocessing import StandardScaler\n","\n","# creates an StandardScaler object\n","sc = StandardScaler()\n","\n","# uses the fit_transform method of a StandardScaler instance to standardize a \n","# subset of features in the X_train array\n","X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n","\n","# applies the transformation learned from the StandardScaler instance (sc) \n","# to standardize a subset of features in the X_test array\n","X_test[:, 3:] = sc.transform(X_test[:, 3:])\n"],"metadata":{"id":"oGpuDVTzQG69","executionInfo":{"status":"ok","timestamp":1684051357899,"user_tz":-330,"elapsed":492,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSgTv94WSAaX","executionInfo":{"status":"ok","timestamp":1684051360794,"user_tz":-330,"elapsed":484,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"d5a3d4ad-321c-435e-8786-949d2c1afacc"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUfn-1IISARu","executionInfo":{"status":"ok","timestamp":1684051364363,"user_tz":-330,"elapsed":469,"user":{"displayName":"Anshu Sinha","userId":"03915781437667046208"}},"outputId":"8e744435-d439-4269-924a-d1323973fd2c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n"," [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"]}]}]}